{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[38:23:51.925572573] [3000998] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera_manager.cpp:326 \u001b[0mlibcamera v0.5.0+59-d83ff0a4\n",
      "[38:23:51.932912458] [3001075] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpisp.cpp:720 \u001b[0mlibpisp version v1.2.1 981977ff21f3 29-04-2025 (14:13:50)\n",
      "[38:23:51.942634886] [3001075] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpisp.cpp:1179 \u001b[0mRegistered camera /base/axi/pcie@1000120000/rp1/i2c@88000/imx708@1a to CFE device /dev/media0 and ISP device /dev/media2 using PiSP variant BCM2712_D0\n",
      "[38:23:51.946335968] [3000998] \u001b[1;32m INFO \u001b[1;37mCamera \u001b[1;34mcamera.cpp:1205 \u001b[0mconfiguring streams: (0) 640x480-RGB888 (1) 1536x864-BGGR_PISP_COMP1\n",
      "[38:23:51.946433505] [3001075] \u001b[1;32m INFO \u001b[1;37mRPI \u001b[1;34mpisp.cpp:1483 \u001b[0mSensor: /base/axi/pcie@1000120000/rp1/i2c@88000/imx708@1a - Selected sensor format: 1536x864-SBGGR10_1X10 - Selected CFE format: 1536x864-PC1B\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------\n",
    "# Audience Analysis Script using Hailo-8, DeGirum SDK, and PiCamera2\n",
    "# ----------------------------------------------------------\n",
    "# Models: Face Detection, Age, Gender, Emotion, Embedding\n",
    "# Hardware: Raspberry Pi 5 + Hailo-8 + Camera Module 3\n",
    "# Filename: 000_audience_analysis_live.ipynb\n",
    "# Created date: 01 July 2025\n",
    "# Last modified date: 06 July 2025\n",
    "# Version: 1.0.0\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Sample JSON Output (Single Viewer Record)\n",
    "# ----------------------------------------------------------\n",
    "# {\n",
    "#   \"timestamp\": \"2025-07-10T15:48:27.124567Z\",\n",
    "#   \"location\": {\n",
    "#     \"mac_address\": \"88:A2:9E:1C:49:6F\",\n",
    "#     \"coordinates\": \"3.1319N, 101.6841E\"\n",
    "#   },\n",
    "#   \"env\": {\n",
    "#     \"temp_c\": 29.75,\n",
    "#     \"humidity\": 63.12,\n",
    "#     \"pressure_hPa\": 1008.27,\n",
    "#     \"gas_resistance_ohms\": 12105.89\n",
    "#   },\n",
    "#   \"viewer_id\": \"3c4f9a7e\",\n",
    "#   \"age_est\": 32,\n",
    "#   \"age_score\": 31.78,\n",
    "#   \"gender\": \"Male\",\n",
    "#   \"gender_score\": 0.95,\n",
    "#   \"emotion\": \"happy\",\n",
    "#   \"emotion_score\": 0.91,\n",
    "#   \"attention_duration\": 5.3,\n",
    "#   \"gaze_at_screen\": true\n",
    "# }\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import uuid\n",
    "import random\n",
    "import logging\n",
    "import numpy as np\n",
    "import degirum as dg\n",
    "import degirum_tools\n",
    "import cv2\n",
    "from picamera2 import Picamera2\n",
    "from datetime import datetime\n",
    "from logging.handlers import TimedRotatingFileHandler\n",
    "import bme680\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Configuration\n",
    "# ----------------------------------------------------------\n",
    "preview_camera = False   # set True to see overlays on screen\n",
    "console_output  = False  # set True to also log to console\n",
    "\n",
    "inference_host_address = \"@local\"\n",
    "zoo_url               = \"../models\"\n",
    "token                 = \"\"\n",
    "device_type           = \"HAILORT/HAILO8\"\n",
    "\n",
    "face_det_model_name   = \"retinaface_mobilenet--736x1280_quant_hailort_hailo8_1\"\n",
    "face_embed_model_name = \"arcface_mobilefacenet--112x112_quant_hailort_hailo8_1\"\n",
    "age_model_name        = \"yolov8n_relu6_age--256x256_quant_hailort_hailo8_1\"\n",
    "gender_model_name     = \"yolov8n_relu6_fairface_gender--256x256_quant_hailort_hailo8_1\"\n",
    "emotion_model_name    = \"emotion_recognition_fer2013--64x64_quant_hailort_multidevice_1\"\n",
    "\n",
    "EMB_DIM = 128  # adjust if your embedding is larger\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Logging Setup\n",
    "# ----------------------------------------------------------\n",
    "os.makedirs(\"../logs\", exist_ok=True)\n",
    "logger = logging.getLogger(\"audience_analysis_live\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.handlers.clear()\n",
    "\n",
    "handler = TimedRotatingFileHandler(\n",
    "    \"../logs/audience_analysis_live.log\",\n",
    "    when=\"H\", interval=1, backupCount=4, utc=True\n",
    ")\n",
    "handler.setFormatter(logging.Formatter(\"%(asctime)s [%(levelname)s] %(message)s\"))\n",
    "logger.addHandler(handler)\n",
    "\n",
    "if console_output:\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setFormatter(handler.formatter)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# BME688 Setup\n",
    "# ----------------------------------------------------------\n",
    "def set_bme688_sensor(sensor):\n",
    "    sensor.set_humidity_oversample(bme680.OS_2X)\n",
    "    sensor.set_pressure_oversample(bme680.OS_4X)\n",
    "    sensor.set_temperature_oversample(bme680.OS_8X)\n",
    "    sensor.set_filter(bme680.FILTER_SIZE_3)\n",
    "    sensor.set_gas_status(bme680.ENABLE_GAS_MEAS)\n",
    "\n",
    "try:\n",
    "    bme_sensor = bme680.BME680(bme680.I2C_ADDR_PRIMARY)\n",
    "    set_bme688_sensor(bme_sensor)\n",
    "except (RuntimeError, IOError):\n",
    "    bme_sensor = bme680.BME680(bme680.I2C_ADDR_SECONDARY)\n",
    "    set_bme688_sensor(bme_sensor)\n",
    "\n",
    "def read_bme688_data():\n",
    "    if bme_sensor.get_sensor_data():\n",
    "        return {\n",
    "            \"temp_c\": round(bme_sensor.data.temperature, 2),\n",
    "            \"humidity\": round(bme_sensor.data.humidity, 2),\n",
    "            \"pressure_hPa\": round(bme_sensor.data.pressure, 2),\n",
    "            \"gas_resistance_ohms\": round(bme_sensor.data.gas_resistance, 2)\n",
    "        }\n",
    "    return {\"temp_c\": None, \"humidity\": None, \"pressure_hPa\": None, \"gas_resistance_ohms\": None}\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Camera Streaming Class\n",
    "# ----------------------------------------------------------\n",
    "class CameraStream:\n",
    "    def __init__(self, fps=5):\n",
    "        self.picam2 = Picamera2()\n",
    "        self.interval = 1.0 / fps\n",
    "        self.picam2.configure(self.picam2.create_preview_configuration(\n",
    "            main={\"format\": \"RGB888\"}\n",
    "        ))\n",
    "        self.picam2.start(show_preview=False)\n",
    "        time.sleep(2)\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            start = time.time()\n",
    "            frame = self.picam2.capture_array()\n",
    "            yield frame\n",
    "            elapsed = time.time() - start\n",
    "            time.sleep(max(0, self.interval - elapsed))\n",
    "\n",
    "    def stop(self):\n",
    "        self.picam2.stop()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Utility Functions\n",
    "# ----------------------------------------------------------\n",
    "def cosine_distance(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    \"\"\"1 - cosine similarity\"\"\"\n",
    "    num = np.dot(a, b)\n",
    "    den = np.linalg.norm(a) * np.linalg.norm(b)\n",
    "    return 1.0 - (num / den) if den > 0 else 1.0\n",
    "\n",
    "def draw_overlay(image, emo_res, age_res, gen_res):\n",
    "    for i, r in enumerate(emo_res):\n",
    "        try:\n",
    "            x1, y1, x2, y2 = map(int, r.get(\"bbox\", []))\n",
    "            age   = round(age_res[i].get(\"score\", 0))\n",
    "            g_lbl = gen_res[i].get(\"label\", \"\")\n",
    "            g_sc  = gen_res[i].get(\"score\", 0.0)\n",
    "            emo   = emo_res[i].get(\"label\", \"\")\n",
    "            e_sc  = emo_res[i].get(\"score\", 0.0)\n",
    "\n",
    "            label = f\"{g_lbl} ({g_sc:.2f}) | Age: {age} | {emo} ({e_sc:.2f})\"\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (0,255,255), 2)\n",
    "            (w,h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.45, 1)\n",
    "            cv2.rectangle(image, (x1,y1-22),(x1+w,y1),(0,255,255),-1)\n",
    "            cv2.putText(image, label, (x1,y1-5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,0,0),1)\n",
    "        except:\n",
    "            pass\n",
    "    return image\n",
    "\n",
    "def get_mac_address():\n",
    "    mac = uuid.getnode()\n",
    "    return \":\".join(f\"{(mac>>i)&0xff:02x}\" for i in range(40,-1,-8)).upper()\n",
    "\n",
    "mac_address = get_mac_address()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Run Inference Generator\n",
    "# ----------------------------------------------------------\n",
    "def run_inference(video_source):\n",
    "    for frame in video_source:\n",
    "        yield {\n",
    "            \"emotion\": face_emotion_model.predict(frame),\n",
    "            \"age\":     face_age_model.predict(frame),\n",
    "            \"gender\":  face_gender_model.predict(frame),\n",
    "            \"embedding\": face_embed_model_comp.predict(frame)\n",
    "        }\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# ViewerTracker: IoU + Embedding Matching\n",
    "# ----------------------------------------------------------\n",
    "class ViewerTracker:\n",
    "    def __init__(self, iou_threshold=0.3, emb_threshold=0.4,\n",
    "                 w_iou=0.5, w_emb=0.5, timeout_sec=10):\n",
    "        self.iou_thr = iou_threshold\n",
    "        self.emb_thr = emb_threshold\n",
    "        self.w_iou   = w_iou\n",
    "        self.w_emb   = w_emb\n",
    "        self.timeout = timeout_sec\n",
    "        self.tracks  = {}  # id -> {'bbox', 'emb', 'last_seen'}\n",
    "\n",
    "    @staticmethod\n",
    "    def _iou(a, b):\n",
    "        xA, yA = max(a[0],b[0]), max(a[1],b[1])\n",
    "        xB, yB = min(a[2],b[2]), min(a[3],b[3])\n",
    "        inter = max(0, xB-xA) * max(0, yB-yA)\n",
    "        areaA = (a[2]-a[0])*(a[3]-a[1])\n",
    "        areaB = (b[2]-b[0])*(b[3]-b[1])\n",
    "        uni   = areaA + areaB - inter\n",
    "        return inter/uni if uni>0 else 0\n",
    "\n",
    "    def _clean(self):\n",
    "        now = time.time()\n",
    "        for tid in list(self.tracks):\n",
    "            if now - self.tracks[tid]['last_seen'] > self.timeout:\n",
    "                del self.tracks[tid]\n",
    "\n",
    "    def update(self, det_bboxes, det_embs):\n",
    "        self._clean()\n",
    "        T = list(self.tracks.keys())\n",
    "        N, M = len(T), len(det_bboxes)\n",
    "\n",
    "        # no existing tracks → all new\n",
    "        if N == 0:\n",
    "            out = []\n",
    "            for bb, emb in zip(det_bboxes, det_embs):\n",
    "                nid = uuid.uuid4().hex[:8]\n",
    "                self.tracks[nid] = {'bbox': bb, 'emb': emb,\n",
    "                                     'last_seen': time.time()}\n",
    "                out.append((nid, True))\n",
    "            return out\n",
    "\n",
    "        # build cost matrix\n",
    "        cost = np.zeros((N, M), dtype=np.float32)\n",
    "        for i, tid in enumerate(T):\n",
    "            tb = self.tracks[tid]['bbox']\n",
    "            te = self.tracks[tid]['emb']\n",
    "            for j, (db, de) in enumerate(zip(det_bboxes, det_embs)):\n",
    "                iou_score = self._iou(tb, db)\n",
    "                emb_dist  = cosine_distance(te, de)\n",
    "                cost[i,j] = self.w_iou*(1-iou_score) + self.w_emb*emb_dist\n",
    "\n",
    "        # Hungarian assignment\n",
    "        rows, cols = linear_sum_assignment(cost)\n",
    "        results = [None]*M\n",
    "\n",
    "        # accept matches under one of the thresholds\n",
    "        for r, c in zip(rows, cols):\n",
    "            tid = T[r]\n",
    "            iou_score = self._iou(self.tracks[tid]['bbox'], det_bboxes[c])\n",
    "            emb_dist  = cosine_distance(self.tracks[tid]['emb'], det_embs[c])\n",
    "            logger.debug(f\"[Tracker] comparing track {tid} ? det {c}: IoU={iou_score:.2f}, emb_dist={emb_dist:.2f}\")\n",
    "            if iou_score >= self.iou_thr or emb_dist <= self.emb_thr:\n",
    "                self.tracks[tid].update({\n",
    "                    'bbox': det_bboxes[c],\n",
    "                    'emb':  det_embs[c],\n",
    "                    'last_seen': time.time()\n",
    "                })\n",
    "                results[c] = (tid, False)\n",
    "            else:\n",
    "                logger.debug(f\"[Tracker] rejecting match (IoU<{self.iou_thr} AND emb_dist>{self.emb_thr})\")\n",
    "\n",
    "        # unmatched → new\n",
    "        for j in range(M):\n",
    "            if results[j] is None:\n",
    "                nid = uuid.uuid4().hex[:8]\n",
    "                self.tracks[nid] = {\n",
    "                    'bbox': det_bboxes[j],\n",
    "                    'emb':  det_embs[j],\n",
    "                    'last_seen': time.time()\n",
    "                }\n",
    "                results[j] = (nid, True)\n",
    "\n",
    "        return results\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Load Models & Compound Pipelines\n",
    "# ----------------------------------------------------------\n",
    "# Load Face Detection Model\n",
    "face_det_model = dg.load_model(\n",
    "    model_name=face_det_model_name,\n",
    "    inference_host_address=inference_host_address,\n",
    "    zoo_url=zoo_url,\n",
    "    token=token,\n",
    "    device_type=device_type\n",
    ")\n",
    "face_det_model.overlay_color = [(255, 255, 0), (0, 255, 0)]\n",
    "\n",
    "# Load Face Embedding Model\n",
    "face_embed_model = dg.load_model(\n",
    "    model_name=face_embed_model_name,\n",
    "    inference_host_address=inference_host_address,\n",
    "    zoo_url=zoo_url,\n",
    "    token=token,\n",
    "    device_type=device_type\n",
    ")\n",
    "\n",
    "# Load Age Estimation Model\n",
    "age_model = dg.load_model(\n",
    "    model_name=age_model_name,\n",
    "    inference_host_address=inference_host_address,\n",
    "    zoo_url=zoo_url,\n",
    "    token=token,\n",
    "    device_type=device_type\n",
    ")\n",
    "\n",
    "# Load Gender Classification Model\n",
    "gender_model = dg.load_model(\n",
    "    model_name=gender_model_name,\n",
    "    inference_host_address=inference_host_address,\n",
    "    zoo_url=zoo_url,\n",
    "    token=token,\n",
    "    device_type=device_type\n",
    ")\n",
    "\n",
    "# Load Emotion Recognition Model\n",
    "emotion_model = dg.load_model(\n",
    "    model_name=emotion_model_name,\n",
    "    inference_host_address=inference_host_address,\n",
    "    zoo_url=zoo_url,\n",
    "    token=token,\n",
    "    device_type=device_type\n",
    ")\n",
    "\n",
    "face_emotion_model  = degirum_tools.CroppingAndClassifyingCompoundModel(face_det_model, emotion_model)\n",
    "face_age_model      = degirum_tools.CroppingAndClassifyingCompoundModel(face_det_model, age_model)\n",
    "face_gender_model   = degirum_tools.CroppingAndClassifyingCompoundModel(face_det_model, gender_model)\n",
    "face_embed_model_comp = degirum_tools.CroppingAndClassifyingCompoundModel(face_det_model, face_embed_model)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Main Runtime\n",
    "# ----------------------------------------------------------\n",
    "video_source = CameraStream(fps=5)\n",
    "tracker = ViewerTracker(\n",
    "    iou_threshold=0.2,    # a little lower to catch small overlaps\n",
    "    emb_threshold=0.6,    # since embeddings are normalized, distances ? [0,2]\n",
    "    w_iou=0.5,\n",
    "    w_emb=0.5,\n",
    "    timeout_sec=10\n",
    ")\n",
    "\n",
    "try:\n",
    "    with degirum_tools.Display(\"Audience Analysis\") as disp:\n",
    "        for results in run_inference(video_source):\n",
    "            emo_res = results[\"emotion\"].results\n",
    "            age_res = results[\"age\"].results\n",
    "            gen_res = results[\"gender\"].results\n",
    "            emb_res = results[\"embedding\"].results\n",
    "\n",
    "            if not emo_res:\n",
    "                continue\n",
    "\n",
    "            bboxes = [r[\"bbox\"] for r in emo_res]\n",
    "            embs   = [\n",
    "                np.array(r.get(\"data\", [np.zeros(EMB_DIM)])[0], dtype=np.float32)\n",
    "                for r in emb_res\n",
    "            ]\n",
    "\n",
    "            assignments = tracker.update(bboxes, embs)\n",
    "\n",
    "            frame    = results[\"emotion\"].image\n",
    "            env_data = read_bme688_data()\n",
    "            min_len  = min(len(emo_res), len(age_res), len(gen_res), len(embs))\n",
    "\n",
    "            if preview_camera:\n",
    "                frame = draw_overlay(frame, emo_res, age_res, gen_res)\n",
    "                disp.show(frame)\n",
    "\n",
    "            for i in range(min_len):\n",
    "                vid, is_new = assignments[i]\n",
    "                out = {\n",
    "                    \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "                    \"location\": {\n",
    "                        \"mac_address\": mac_address,\n",
    "                        \"coordinates\": \"3.1319N, 101.6841E\"\n",
    "                    },\n",
    "                    \"env\": env_data,\n",
    "                    \"viewer_id\": vid,\n",
    "                    \"is_new_viewer\": is_new,\n",
    "                    \"age_est\": round(age_res[i].get(\"score\", 0)),\n",
    "                    \"age_score\": age_res[i].get(\"score\", 0.0),\n",
    "                    \"gender\": gen_res[i].get(\"label\", \"\"),\n",
    "                    \"gender_score\": gen_res[i].get(\"score\", 0.0),\n",
    "                    \"emotion\": emo_res[i].get(\"label\", \"\"),\n",
    "                    \"emotion_score\": emo_res[i].get(\"score\", 0.0),\n",
    "                    \"attention_duration\": round(random.uniform(2.0, 7.5), 1),\n",
    "                    \"gaze_at_screen\": random.choice([True, False])\n",
    "                }\n",
    "                logger.debug(json.dumps(out))\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logger.info(\"Interrupted by user.\")\n",
    "finally:\n",
    "    video_source.stop()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai_digital_signage_env)",
   "language": "python",
   "name": "ai_digital_signage_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
